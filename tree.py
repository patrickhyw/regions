from __future__ import annotations

import argparse
import json
from collections import Counter
from dataclasses import dataclass
from pathlib import Path
from typing import Literal

from nltk.corpus import wordnet as wn
from nltk.corpus.reader.wordnet import Synset
from pydantic import BaseModel, ConfigDict, ValidationError, model_validator
from treegen.util import get_tree_path


class KnowledgeNode(BaseModel):
    model_config = ConfigDict(frozen=True)

    concept: str
    children: list[KnowledgeNode] = []

    def concepts(self) -> list[str]:
        """Recursively collect all concepts in this subtree."""
        result = [self.concept]
        for child in self.children:
            result.extend(child.concepts())
        return result


# Handles global logic across the entire tree that isn't easily writable as a
# recursive function. The model validator is one example, as validating unique
# concepts in every subtree would give quadratic time complexity.
class KnowledgeTree(BaseModel):
    # Set hide_input_in_errors=True because the input is the entire tree, which is
    # too large to display in the error message.
    model_config = ConfigDict(frozen=True, hide_input_in_errors=True)

    root: KnowledgeNode

    @model_validator(mode="after")
    def _validate_unique_concepts(self) -> KnowledgeTree:
        counts = Counter(self.root.concepts())
        duplicates = {c for c, n in counts.items() if n > 1}
        if duplicates:
            raise ValueError(f"Duplicate concepts: {duplicates}")
        return self


@dataclass(frozen=True)
class TreeSpec:
    """Specification for a preconfigured tree."""

    root_synset: str
    dag_handling: Literal["disallow", "collapse"]
    num_lemmas: int | Literal["all"]
    include_definition: bool
    dup_handling: Literal["disallow", "prune"]
    replace: dict[str, str | None]
    # None means no validation on tree size.
    validate_tree_size: int | None


# Used to replace ambiguous/irrelevant concepts when using the "minimal" setup
# (num_lemmas=1 and include_definition=False) for concepts under the "animal"
# root. Generated by Opus 4.6. See animal_replace.json.
_ANIMAL_REPLACE_PATH = Path(__file__).parent / "animal_replace.json"
with open(_ANIMAL_REPLACE_PATH) as _f:
    ANIMAL_REPLACE: dict[str, str | None] = json.load(_f)


TREE_DIRECTORY: dict[str, TreeSpec] = {
    "animalmin": TreeSpec(
        root_synset="animal.n.01",
        dag_handling="collapse",
        num_lemmas=1,
        include_definition=False,
        dup_handling="prune",
        replace=ANIMAL_REPLACE,
        validate_tree_size=None,
    ),
    "mammalmin": TreeSpec(
        root_synset="mammal.n.01",
        dag_handling="collapse",
        num_lemmas=1,
        include_definition=False,
        dup_handling="prune",
        replace=ANIMAL_REPLACE,
        validate_tree_size=1126,
    ),
    "carnivoremin": TreeSpec(
        root_synset="carnivore.n.01",
        dag_handling="disallow",
        num_lemmas=1,
        include_definition=False,
        dup_handling="prune",
        replace=ANIMAL_REPLACE,
        validate_tree_size=359,
    ),
    "bovidmin": TreeSpec(
        root_synset="bovid.n.01",
        dag_handling="disallow",
        num_lemmas=1,
        include_definition=False,
        dup_handling="prune",
        replace=ANIMAL_REPLACE,
        validate_tree_size=121,
    ),
    "primate": TreeSpec(
        root_synset="primate.n.02",
        dag_handling="disallow",
        num_lemmas=1,
        include_definition=False,
        dup_handling="disallow",
        replace=ANIMAL_REPLACE,
        validate_tree_size=103,
    ),
    "monkey": TreeSpec(
        root_synset="monkey.n.01",
        dag_handling="disallow",
        num_lemmas=1,
        include_definition=False,
        dup_handling="disallow",
        replace=ANIMAL_REPLACE,
        validate_tree_size=39,
    ),
    "oldworldmonkey": TreeSpec(
        root_synset="old_world_monkey.n.01",
        dag_handling="disallow",
        num_lemmas=1,
        include_definition=False,
        dup_handling="disallow",
        replace=ANIMAL_REPLACE,
        validate_tree_size=22,
    ),
}


def build_tree(
    root: Synset,
    dag_handling: Literal["disallow", "collapse"] = "disallow",
    num_lemmas: int | Literal["all"] = 1,
    include_definition: bool = False,
    duplicate_handling: Literal["disallow", "prune"] = "disallow",
    replace: dict[str, str | None] | None = None,
) -> KnowledgeTree:
    """Build a KnowledgeTree by following hyponyms down from root.

    The transitive closure of root may be a DAG. The behavior in this case is
    determined by dag_handling:
      - "disallow": Raises ValueError.
      - "collapse": Collapse synsets to their most frequent parent. synset.hypernyms()
        returns the synset's hypernyms from most to least frequent.

    Even after the DAG issue is resolved, the tree may still contain duplicate concepts
    since different synsets may have the same lemma names. The behavior in this case
    is determined by num_lemmas, include_definition, and duplicate_handling. num_lemmas
    and include_definition are applied first, then duplicate_handling is applied:
      - num_lemmas:
        - n >= 1: Collapse synsets to their n most frequent lemma names.
        - "all": Use all lemma names.
        - Lemmas are delimited by ', '.
      - include_definition:
        - True: Include the definition in the concept.
        - False: Do not include the definition in the concept.
        - The definition is delimited by a ' - '.
      - duplicate_handling:
        - "disallow": Raises ValueError if any concept is duplicated.
        - "prune": Prune the subtrees of duplicate concepts. Among non-renamed
          duplicates (same concept string before and after replace), keep the one
          with the lowest sense number (e.g. keep "dog.n.01" over "dog.n.02"). If
          all duplicates were renamed by replace, keep the one with the
          lexicographically smallest synset name for determinism.
            - We prune all duplicate concepts at once, even if some of them
              would no longer be duplicates assuming others were pruned.
              While this can slightly overprune, it's the simplest way to
              prune deterministically.

    Some common approaches to concept handling are:
      - Optimistic (default): num_lemmas=1, include_definition=False,
        duplicate_handling="disallow"
          - This ensures that every concept is a single word ("word" as in the WordNet
            definition, which sometimes means multiple words) and that nothing is
            pruned. However, it will only be feasible for small trees.
      - Minimalist: num_lemmas=1, include_definition=False, duplicate_handling="prune"
          - This ensures that every concept is a single word and works for all trees.
      - Maximalist: num_lemmas="all", include_definition=True,
        duplicate_handling="disallow"
          - This ensures that no concepts are pruned while guaranteeing uniqueness.
      - This repo only uses the "minimalist" setup right now.

    The replace dictionary is used to replace concept strings with new strings and
    is applied after concept formatting but before duplicate handling. This is
    useful for removing concepts that don't make sense (e.g. how "world" is a
    hypernym of "homo") or concepts that are ambiguous (e.g. how "drill" is meant
    to mean the monkey named "drill"). All keys not matching any concept in the
    tree are silently ignored.

    The raised ValueError will explicitly mention whether the issue is due to DAG
    handling or duplicate concepts.
    """

    if replace is None:
        replace = {}

    if isinstance(num_lemmas, int) and num_lemmas < 1:
        raise ValueError("num_lemmas must be >= 1")

    # Collect unique synsets, detecting DAGs during traversal.
    all_synsets: set[Synset] = set()
    is_dag = False
    stack = [root]
    while stack:
        synset = stack.pop()
        if synset in all_synsets:
            is_dag = True
            continue
        all_synsets.add(synset)
        stack.extend(synset.hyponyms())

    if dag_handling == "disallow":
        if is_dag:
            raise ValueError("DAG detected while dag_handling='disallow'")
    elif dag_handling != "collapse":
        raise ValueError(f"Invalid dag_handling: {dag_handling}")

    # Build parent->children map. Each child is assigned to its first (most
    # frequent) in-tree hypernym. In non-DAG cases this is the only parent;
    # in collapse mode this picks the primary parent.
    children_map: dict[Synset, list[Synset]] = {s: [] for s in all_synsets}
    for parent in all_synsets:
        for child in parent.hyponyms():
            in_tree_hypernyms = [h for h in child.hypernyms() if h in all_synsets]
            if in_tree_hypernyms[0] == parent:
                children_map[parent].append(child)

    def _concept_str(synset: Synset) -> str:
        raw = (
            synset.lemma_names()
            if num_lemmas == "all"
            else synset.lemma_names()[:num_lemmas]
        )
        names = [n.replace("_", " ") for n in raw]
        result = ", ".join(names)
        if include_definition:
            result += " - " + synset.definition()
        return result

    def _effective_concept(synset: Synset) -> str | None:
        concept = _concept_str(synset)
        return replace.get(concept, concept)

    # Apply replace removals (None values) before pruning so that children of
    # removed nodes are promoted before duplicate detection can discard them.
    if _effective_concept(root) is None:
        raise ValueError("Cannot remove the root concept via replace")

    removed: set[Synset] = {s for s in children_map if _effective_concept(s) is None}

    def _surviving_children(synset: Synset) -> list[Synset]:
        result: list[Synset] = []
        for child in children_map[synset]:
            if child in removed:
                result.extend(_surviving_children(child))
            else:
                result.append(child)
        return result

    for parent in list(children_map):
        if parent in removed:
            continue
        children_map[parent] = _surviving_children(parent)
    for s in removed:
        del children_map[s]

    # Prune duplicate concepts before converting to KnowledgeTree. Don't do anything if
    # duplicate_handling is "disallow" as the KnowledgeTree validator will catch this.
    if duplicate_handling == "prune":
        concept_to_synsets: dict[str, list[Synset]] = {}
        for synset in children_map:
            concept = _effective_concept(synset)
            assert concept is not None  # None synsets already removed.
            concept_to_synsets.setdefault(concept, []).append(synset)

        synsets_to_prune: set[Synset] = set()
        for synsets in concept_to_synsets.values():
            if len(synsets) <= 1:
                continue
            # Prefer synsets whose concept wasn't changed by replace.
            non_renamed = [
                s for s in synsets if _concept_str(s) == _effective_concept(s)
            ]
            if non_renamed:
                # Non-renamed synsets share the same concept string, so they
                # must have the same first lemma and POS. Keep the lowest
                # sense number.
                parsed = []
                for s in non_renamed:
                    _, _, number = s.name().rsplit(".", 2)
                    parsed.append((s, int(number)))
                winner = min(parsed, key=lambda t: t[1])[0]
            else:
                # All synsets were renamed to the same concept. Keep the
                # one with the lexicographically smallest name for
                # determinism (sense numbers aren't comparable across
                # different base lemmas).
                winner = min(synsets, key=lambda s: s.name())
            synsets_to_prune.update(s for s in synsets if s is not winner)

        for parent in children_map:
            children_map[parent] = [
                c for c in children_map[parent] if c not in synsets_to_prune
            ]
    elif duplicate_handling != "disallow":
        raise ValueError(f"Invalid duplicate_handling: {duplicate_handling}")

    # Convert to KnowledgeTree.
    def _to_knowledge_node(synset: Synset) -> KnowledgeNode:
        children = [_to_knowledge_node(c) for c in children_map[synset]]
        concept = _effective_concept(synset)
        assert concept is not None  # None synsets already removed.
        return KnowledgeNode(concept=concept, children=children)

    try:
        return KnowledgeTree(root=_to_knowledge_node(root))
    except ValidationError as e:
        if "Duplicate concepts" in str(e):
            raise ValueError(f"Duplicate concepts in tree, errors: {e.errors()}") from e
        raise


def main(name: str) -> None:
    """Look up *name* in TREE_DIRECTORY, build the tree, and write to disk."""
    spec = TREE_DIRECTORY[name]
    root = wn.synset(spec.root_synset)
    tree = build_tree(
        root,
        dag_handling=spec.dag_handling,
        num_lemmas=spec.num_lemmas,
        include_definition=spec.include_definition,
        duplicate_handling=spec.dup_handling,
        replace=spec.replace,
    )
    if spec.validate_tree_size is not None:
        actual = len(tree.root.concepts())
        assert actual == spec.validate_tree_size, (
            f"expected {spec.validate_tree_size} concepts, got {actual}"
        )
    path = get_tree_path(f"wordnet_{name}")
    path.write_text(tree.model_dump_json(indent=2))
    print(f"Wrote {path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Build a WordNet tree from a TREE_DIRECTORY entry."
    )
    parser.add_argument(
        "name", choices=TREE_DIRECTORY.keys(), help="Tree name to build."
    )
    args = parser.parse_args()
    main(args.name)
